{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Ambiguity and Improving Clarity in Prompt Engineering\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial focuses on two critical aspects of prompt engineering: identifying and resolving ambiguous prompts, and techniques for writing clearer prompts. These skills are essential for effective communication with AI models and obtaining more accurate and relevant responses.\n",
    "\n",
    "## Motivation\n",
    "\n",
    "Ambiguity in prompts can lead to inconsistent or irrelevant AI responses, while lack of clarity can result in misunderstandings and inaccurate outputs. By mastering these aspects of prompt engineering, you can significantly improve the quality and reliability of AI-generated content across various applications.\n",
    "\n",
    "## Key Components\n",
    "\n",
    "1. Identifying ambiguous prompts\n",
    "2. Strategies for resolving ambiguity\n",
    "3. Techniques for writing clearer prompts\n",
    "4. Practical examples and exercises\n",
    "\n",
    "## Method Details\n",
    "\n",
    "We'll use OpenAI's GPT model and the LangChain library to demonstrate various techniques for handling ambiguity and improving clarity in prompts. The tutorial will cover:\n",
    "\n",
    "1. Setting up the environment and necessary libraries\n",
    "2. Analyzing ambiguous prompts and their potential interpretations\n",
    "3. Implementing strategies to resolve ambiguity, such as providing context and specifying parameters\n",
    "4. Exploring techniques for writing clearer prompts, including using specific language and structured formats\n",
    "5. Practical exercises to apply these concepts in real-world scenarios\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "By the end of this tutorial, you'll have a solid understanding of how to identify and resolve ambiguity in prompts, as well as techniques for crafting clearer prompts. These skills will enable you to communicate more effectively with AI models, resulting in more accurate and relevant outputs across various applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain==0.3.2\n",
      "  Downloading langchain-0.3.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.13/site-packages (from langchain==0.3.2) (6.0.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.13/site-packages (from langchain==0.3.2) (2.0.44)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain==0.3.2)\n",
      "  Downloading aiohttp-3.13.2-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.8 (from langchain==0.3.2)\n",
      "  Downloading langchain_core-0.3.80-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain==0.3.2)\n",
      "  Downloading langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.3.2)\n",
      "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting numpy<2.0.0,>=1.26.0 (from langchain==0.3.2)\n",
      "  Downloading numpy-1.26.4.tar.gz (15.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/conda/lib/python3.13/site-packages (from langchain==0.3.2) (2.12.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.13/site-packages (from langchain==0.3.2) (2.32.5)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain==0.3.2)\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.2)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.2)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.2) (25.4.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.2)\n",
      "  Downloading frozenlist-1.8.0-cp313-cp313-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.2)\n",
      "  Downloading multidict-6.7.0-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.2)\n",
      "  Downloading propcache-0.4.1-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.2)\n",
      "  Downloading yarl-1.22.0-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
      "INFO: pip is looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-core<0.4.0,>=0.3.8 (from langchain==0.3.2)\n",
      "  Downloading langchain_core-0.3.79-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading langchain_core-0.3.78-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading langchain_core-0.3.77-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading langchain_core-0.3.76-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading langchain_core-0.3.75-py3-none-any.whl.metadata (5.7 kB)\n",
      "  Downloading langchain_core-0.3.74-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading langchain_core-0.3.73-py3-none-any.whl.metadata (5.8 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading langchain_core-0.3.72-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading langchain_core-0.3.71-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading langchain_core-0.3.70-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading langchain_core-0.3.69-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading langchain_core-0.3.68-py3-none-any.whl.metadata (5.8 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading langchain_core-0.3.67-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading langchain_core-0.3.66-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading langchain_core-0.3.65-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading langchain_core-0.3.64-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading langchain_core-0.3.63-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.8->langchain==0.3.2) (1.33)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core<0.4.0,>=0.3.8->langchain==0.3.2)\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.8->langchain==0.3.2) (4.15.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.8->langchain==0.3.2) (3.0.0)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain==0.3.2)\n",
      "  Downloading langchain_text_splitters-0.3.10-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.13/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.2) (0.28.1)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain==0.3.2)\n",
      "  Downloading orjson-3.11.4-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain==0.3.2)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.2) (4.11.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.2) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.2) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.2) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/conda/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.2) (0.16.0)\n",
      "Requirement already satisfied: pip>=25.2 in /opt/conda/lib/python3.13/site-packages (from langchain-text-splitters<0.4.0,>=0.3.0->langchain==0.3.2) (25.3)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain==0.3.2)\n",
      "  Downloading langchain_text_splitters-0.3.9-py3-none-any.whl.metadata (1.9 kB)\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.2) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /opt/conda/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.2) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/conda/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.2) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.13/site-packages (from requests<3,>=2->langchain==0.3.2) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.13/site-packages (from requests<3,>=2->langchain==0.3.2) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in /opt/conda/lib/python3.13/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.2) (3.2.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.2) (1.3.1)\n",
      "Downloading langchain-0.3.2-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.13.2-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.63-py3-none-any.whl (438 kB)\n",
      "Downloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
      "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading multidict-6.7.0-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (254 kB)\n",
      "Downloading orjson-3.11.4-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (136 kB)\n",
      "Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading yarl-1.22.0-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (377 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading frozenlist-1.8.0-cp313-cp313-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (234 kB)\n",
      "Downloading propcache-0.4.1-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (204 kB)\n",
      "Building wheels for collected packages: numpy\n",
      "  Building wheel for numpy (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for numpy: filename=numpy-1.26.4-cp313-cp313-linux_x86_64.whl size=9088503 sha256=74e2903470bc1d006b1e8a3e0f4db993a6c49b4fbd644bb46dee7e98b9fa2574\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/8b/2d/9f/b6b46373f328e2ef50388915d351ccacbedac929459b5459bf\n",
      "Successfully built numpy\n",
      "Installing collected packages: tenacity, propcache, packaging, orjson, numpy, multidict, frozenlist, aiohappyeyeballs, yarl, requests-toolbelt, aiosignal, langsmith, aiohttp, langchain-core, langchain-text-splitters, langchain\n",
      "\u001b[2K  Attempting uninstall: packaging\n",
      "\u001b[2K    Found existing installation: packaging 25.0\n",
      "\u001b[2K    Uninstalling packaging-25.0:\n",
      "\u001b[2K      Successfully uninstalled packaging-25.0\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/16\u001b[0m [langchain]16\u001b[0m [langchain]core]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 frozenlist-1.8.0 langchain-0.3.2 langchain-core-0.3.63 langchain-text-splitters-0.3.8 langsmith-0.1.147 multidict-6.7.0 numpy-1.26.4 orjson-3.11.4 packaging-24.2 propcache-0.4.1 requests-toolbelt-1.0.0 tenacity-8.5.0 yarl-1.22.0\n",
      "Collecting langchain-openai==0.2.2\n",
      "  Downloading langchain_openai-0.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.9 in /opt/conda/lib/python3.13/site-packages (from langchain-openai==0.2.2) (0.3.63)\n",
      "Collecting openai<2.0.0,>=1.40.0 (from langchain-openai==0.2.2)\n",
      "  Downloading openai-1.109.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai==0.2.2)\n",
      "  Downloading tiktoken-0.12.0-cp313-cp313-manylinux_2_28_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.126 in /opt/conda/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.9->langchain-openai==0.2.2) (0.1.147)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/conda/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.9->langchain-openai==0.2.2) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.9->langchain-openai==0.2.2) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.9->langchain-openai==0.2.2) (6.0.3)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.9->langchain-openai==0.2.2) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.9->langchain-openai==0.2.2) (4.15.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /opt/conda/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.9->langchain-openai==0.2.2) (2.12.4)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.9->langchain-openai==0.2.2) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.9->langchain-openai==0.2.2) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.9->langchain-openai==0.2.2) (3.11.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.9->langchain-openai==0.2.2) (2.32.5)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.9->langchain-openai==0.2.2) (1.0.0)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.9->langchain-openai==0.2.2) (4.11.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.9->langchain-openai==0.2.2) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.9->langchain-openai==0.2.2) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.9->langchain-openai==0.2.2) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/conda/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.9->langchain-openai==0.2.2) (0.16.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.13/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.2) (1.9.0)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.2)\n",
      "  Downloading jiter-0.12.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.13/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.2) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.13/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.2) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.13/site-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.9->langchain-openai==0.2.2) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /opt/conda/lib/python3.13/site-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.9->langchain-openai==0.2.2) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/conda/lib/python3.13/site-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.9->langchain-openai==0.2.2) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.13/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.9->langchain-openai==0.2.2) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.13/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.9->langchain-openai==0.2.2) (2.5.0)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai==0.2.2)\n",
      "  Downloading regex-2025.11.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Downloading langchain_openai-0.2.2-py3-none-any.whl (49 kB)\n",
      "Downloading openai-1.109.1-py3-none-any.whl (948 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m948.6/948.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jiter-0.12.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (361 kB)\n",
      "Downloading tiktoken-0.12.0-cp313-cp313-manylinux_2_28_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2025.11.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (803 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.5/803.5 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: regex, jiter, tiktoken, openai, langchain-openai\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [langchain-openai][langchain-openai]\n",
      "\u001b[1A\u001b[2KSuccessfully installed jiter-0.12.0 langchain-openai-0.2.2 openai-1.109.1 regex-2025.11.3 tiktoken-0.12.0\n",
      "Collecting python-dotenv==1.0.1\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain==0.3.2\n",
    "!pip install langchain-openai==0.2.2\n",
    "!pip install python-dotenv==1.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "# from langchain import PromptTemplate\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Set up OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Initialize the language model\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.environ[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Ambiguous Prompts\n",
    "\n",
    "Let's start by examining some ambiguous prompts and analyzing their potential interpretations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Tell me about the bank.\n",
      "The prompt \"Tell me about the bank.\" is ambiguous for several reasons:\n",
      "\n",
      "1. **Type of Bank**: The term \"bank\" can refer to various types of financial institutions, such as:\n",
      "   - Commercial banks (which offer services like savings and checking accounts).\n",
      "   - Investment banks (which focus on underwriting and capital raising).\n",
      "   - Central banks (which manage a nation's currency and monetary policy).\n",
      "   - Credit unions (which are member-owned financial cooperatives).\n",
      "   - Online banks (which operate primarily through digital platforms).\n",
      "\n",
      "2. **Contextual Information**: The prompt does not specify what aspect of the bank is of interest. Possible areas of focus could include:\n",
      "   - History (e.g., the founding and evolution of a specific bank).\n",
      "   - Services offered (e.g., loans, mortgages, investment options).\n",
      "   - Financial performance (e.g., recent earnings, stock performance).\n",
      "   - Regulations (e.g., how it complies with banking laws).\n",
      "   - Customer experiences (e.g., reviews and satisfaction ratings).\n",
      "\n",
      "3. **Geographical Reference**: The term \"bank\" could refer to a specific institution in a particular location or a general concept. Without a specific context, it could be interpreted as:\n",
      "   - A local bank in a specific city or region.\n",
      "   - A well-known global bank (like JPMorgan Chase or HSBC).\n",
      "   - A bank within a particular country, which may have different regulations or practices.\n",
      "\n",
      "4. **Purpose of Inquiry**: The intent behind the request is unclear. The prompt could imply:\n",
      "   - A request for a general overview of banking.\n",
      "   - A detailed analysis of a specific bank's operations.\n",
      "   - An exploration of the banking sector's impact on the economy.\n",
      "   - An inquiry about customer services or experiences with a particular bank.\n",
      "\n",
      "### Possible Interpretations:\n",
      "\n",
      "1. **Historical Overview**: A request for the history and development of a specific bank (e.g., \"Tell me about the history of Bank of America\").\n",
      "   \n",
      "2. **Services and Products Offered**: An inquiry about the types of financial products and services available at a bank (e.g., \"What services does Citibank offer?\").\n",
      "\n",
      "3. **Comparative Analysis**: A prompt for comparison between different banks or banking services (e.g., \"How does Chase compare to Wells Fargo?\").\n",
      "\n",
      "4. **Customer Experiences**: A request for information about customer satisfaction and experiences with a specific bank (e.g., \"What do customers think about Bank of America?\").\n",
      "\n",
      "5. **Regulatory Environment**: An interest in the regulations affecting banks in a particular jurisdiction (e.g., \"What are the regulations governing banks in the EU?\").\n",
      "\n",
      "6. **Economic Impact**: A question about the role of banks in the economy (e.g., \"How do banks influence economic growth?\").\n",
      "\n",
      "In summary, the ambiguity of the prompt arises from the lack of specificity regarding the type of bank, the context or aspect of banking being addressed, the geographical reference, and the purpose of the inquiry. Each of these factors could lead to vastly different responses based on the interpretation taken.\n",
      "--------------------------------------------------\n",
      "Prompt: What's the best way to get to school?\n",
      "The prompt \"What's the best way to get to school?\" is ambiguous for several reasons:\n",
      "\n",
      "1. **Mode of Transportation**: The phrase \"best way\" can refer to different modes of transportation, such as walking, biking, driving, or taking public transit. Each mode may have its own advantages and disadvantages depending on various factors.\n",
      "\n",
      "2. **Criteria for \"Best\"**: The term \"best\" is subjective and can vary based on individual priorities. For example:\n",
      "   - **Time**: The quickest route.\n",
      "   - **Cost**: The least expensive option.\n",
      "   - **Safety**: The safest route to avoid accidents or dangerous areas.\n",
      "   - **Environmental Impact**: The most eco-friendly choice, such as using public transport or biking.\n",
      "   - **Convenience**: The most straightforward route that requires the least effort.\n",
      "\n",
      "3. **Starting Point**: The prompt does not specify the starting point. The \"best way\" to get to school can differ significantly depending on where a person is coming from.\n",
      "\n",
      "4. **Location of School**: There could be multiple schools in the area, and the prompt does not clarify which school is being referred to.\n",
      "\n",
      "5. **Time of Day**: The best route may vary depending on the time of day due to traffic patterns, public transportation schedules, or safety concerns (e.g., less traffic at certain times).\n",
      "\n",
      "6. **Personal Preferences**: Different individuals may have different preferences that affect their choice of route, such as avoiding busy roads or preferring scenic paths.\n",
      "\n",
      "### Possible Interpretations:\n",
      "1. What is the fastest way to get to school from my current location?\n",
      "2. What is the cheapest way to commute to school?\n",
      "3. What is the safest route, considering traffic and neighborhood safety?\n",
      "4. What is the most environmentally friendly way to reach school?\n",
      "5. What route should I take if I want to avoid traffic?\n",
      "6. What are the best walking or biking paths to school?\n",
      "7. What are the options for public transportation to school?\n",
      "\n",
      "Overall, the ambiguity arises from the lack of specificity regarding the mode, criteria, starting point, destination, time considerations, and personal preferences.\n",
      "--------------------------------------------------\n",
      "Prompt: Can you explain the theory?\n",
      "The prompt \"Can you explain the theory?\" is ambiguous for several reasons:\n",
      "\n",
      "1. **Lack of Specificity**: The term \"theory\" is not defined. There are numerous theories across various fields, such as science (e.g., the theory of evolution, quantum theory), philosophy (e.g., social contract theory), or mathematics (e.g., number theory). Without context, it's unclear which theory is being referred to.\n",
      "\n",
      "2. **Target Audience**: The prompt does not specify who the explanation is intended for. The level of detail and complexity required can vary significantly depending on the audience's background knowledge. For example, an explanation for a layperson would differ greatly from one intended for a specialist in the field.\n",
      "\n",
      "3. **Nature of Explanation**: The prompt does not clarify what kind of explanation is desired. Are they looking for a brief overview, a detailed analysis, historical context, practical applications, or critiques of the theory? Each of these requires a different approach.\n",
      "\n",
      "4. **Contextual Factors**: The context in which the question is asked can also influence its meaning. For instance, if asked in a classroom setting, the expectation might lean towards an academic explanation, while in a casual conversation, a more simplified version might be appropriate.\n",
      "\n",
      "### Possible Interpretations\n",
      "\n",
      "1. **Scientific Theory**: The request might be for an explanation of a specific scientific theory, such as the theory of relativity or the theory of plate tectonics.\n",
      "\n",
      "2. **Philosophical Theory**: The inquiry could pertain to a philosophical theory, like utilitarianism or existentialism, requiring a discussion of its principles and implications.\n",
      "\n",
      "3. **Mathematical Theory**: The prompt might be asking for an explanation of a mathematical theory, such as game theory, which would involve mathematical concepts and applications.\n",
      "\n",
      "4. **Social or Behavioral Theory**: The request could relate to theories in social sciences, such as attachment theory or cognitive dissonance theory, focusing on human behavior and interactions.\n",
      "\n",
      "5. **Theoretical Framework**: It could also refer to a theoretical framework used in research or academia, asking for an explanation of its components and how it is applied in practice.\n",
      "\n",
      "6. **Personal Understanding**: The question might be interpreted as a request for the respondent's personal understanding or interpretation of a theory, rather than a textbook definition.\n",
      "\n",
      "In conclusion, the ambiguity arises from the lack of specificity regarding which theory is being discussed, the intended audience, the desired depth of explanation, and the context of the inquiry. Clarifying these elements would help eliminate ambiguity and facilitate a more focused response.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ambiguous_prompts = [\n",
    "    \"Tell me about the bank.\",\n",
    "    \"What's the best way to get to school?\",\n",
    "    \"Can you explain the theory?\"\n",
    "]\n",
    "\n",
    "for prompt in ambiguous_prompts:\n",
    "    analysis_prompt = f\"Analyze the following prompt for ambiguity: '{prompt}'. Explain why it's ambiguous and list possible interpretations.\"\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(llm.invoke(analysis_prompt).content)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resolving Ambiguity\n",
    "\n",
    "Now, let's explore strategies for resolving ambiguity in prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: You are a financial advisor discussing savings accounts.\n",
      "Clarified response: When discussing a bank in the context of savings accounts, there are several key aspects to consider:\n",
      "\n",
      "1. **Types of Banks**: Banks can be traditional brick-and-mortar institutions, online banks, or credit unions. Online banks often offer higher interest rates on savings accounts due to lower overhead costs.\n",
      "\n",
      "2. **Interest Rates**: One of the most important factors to consider is the interest rate offered on savings accounts. Rates can vary significantly between banks, and it's beneficial to shop around for the best rates. Online banks typically offer higher rates compared to traditional banks.\n",
      "\n",
      "3. **Fees and Minimum Balances**: Many banks have fees associated with their savings accounts, such as maintenance fees or fees for falling below a minimum balance. It's essential to understand these fees as they can eat into your savings.\n",
      "\n",
      "4. **Accessibility and Convenience**: Consider how easy it is to access your funds. Many banks offer online and mobile banking, which allows you to manage your savings account conveniently. Additionally, check if the bank has a network of ATMs for easy withdrawals.\n",
      "\n",
      "5. **FDIC Insurance**: Ensure that the bank is insured by the Federal Deposit Insurance Corporation (FDIC) if it is a traditional bank, or by the National Credit Union Administration (NCUA) if it is a credit union. This insurance protects your deposits up to $250,000 per depositor, per institution.\n",
      "\n",
      "6. **Customer Service**: The quality of customer service can vary by bank. Look for banks that offer good support, whether through branches, phone, or online chat.\n",
      "\n",
      "7. **Promotions and Bonuses**: Some banks offer promotional rates or bonuses for opening a new savings account. These can be attractive, but it's important to read the fine print and understand any requirements.\n",
      "\n",
      "8. **Reputation and Reviews**: Research the bank's reputation by reading customer reviews and checking for any regulatory issues. A bank with a solid reputation is more likely to provide reliable service.\n",
      "\n",
      "By considering these factors, you can choose a bank that aligns with your savings goals and provides a secure, efficient way to grow your savings.\n",
      "--------------------------------------------------\n",
      "Context: You are a geographer describing river formations.\n",
      "Clarified response: In the context of river formations, the term \"bank\" refers to the land alongside a river or stream. Banks play a vital role in shaping the river's characteristics and influencing its ecosystem. Here are some key points about river banks:\n",
      "\n",
      "1. **Structure and Composition**: River banks can be composed of various materials, including soil, sand, gravel, and rock. The composition often varies along the length of the river due to factors like erosion, sediment deposition, and vegetation.\n",
      "\n",
      "2. **Types of Banks**: \n",
      "   - **Left Bank**: When facing downstream, the left bank is the side of the river on the left.\n",
      "   - **Right Bank**: Conversely, the right bank is on the right side when looking downstream.\n",
      "   - **High and Low Banks**: Banks can be classified as high or low, depending on their elevation relative to the water level. High banks can reduce the risk of flooding, while low banks may be more susceptible to inundation.\n",
      "\n",
      "3. **Erosion and Deposition**: The dynamics of river flow can lead to erosion of the banks on one side while depositing sediments on the other. This process shapes the river's meanders, creating features like cut banks (areas of erosion) and point bars (areas of deposition).\n",
      "\n",
      "4. **Vegetation**: The banks of a river often support diverse plant life, which plays a crucial role in stabilizing the soil, preventing erosion, and providing habitat for wildlife. Riparian vegetation, which includes trees, shrubs, and grasses, is particularly important for maintaining the health of river ecosystems.\n",
      "\n",
      "5. **Human Interaction**: River banks are often sites of human activity, including agriculture, urban development, and recreation. This interaction can lead to modifications such as levees and flood control structures to manage water flow and reduce flood risk.\n",
      "\n",
      "6. **Ecological Importance**: The health of river banks is critical for maintaining the overall health of river ecosystems. They provide essential habitats for numerous species and contribute to water quality by filtering pollutants and providing shade that regulates water temperature.\n",
      "\n",
      "In summary, river banks are dynamic environments that play a crucial role in the physical, ecological, and human dimensions of river systems. Understanding their characteristics and functions is essential for effective river management and conservation efforts.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def resolve_ambiguity(prompt, context):\n",
    "    \"\"\"\n",
    "    Resolve ambiguity in a prompt by providing additional context.\n",
    "    \n",
    "    Args:\n",
    "    prompt (str): The original ambiguous prompt\n",
    "    context (str): Additional context to resolve ambiguity\n",
    "    \n",
    "    Returns:\n",
    "    str: The AI's response to the clarified prompt\n",
    "    \"\"\"\n",
    "    clarified_prompt = f\"{context}\\n\\nBased on this context, {prompt}\"\n",
    "    return llm.invoke(clarified_prompt).content\n",
    "\n",
    "# Example usage\n",
    "ambiguous_prompt = \"Tell me about the bank.\"\n",
    "contexts = [\n",
    "    \"You are a financial advisor discussing savings accounts.\",\n",
    "    \"You are a geographer describing river formations.\"\n",
    "]\n",
    "\n",
    "for context in contexts:\n",
    "    print(f\"Context: {context}\")\n",
    "    print(f\"Clarified response: {resolve_ambiguity(ambiguous_prompt, context)}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Techniques for Writing Clearer Prompts\n",
    "\n",
    "Let's explore some techniques for writing clearer prompts to improve AI responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_prompt_clarity(original_prompt, improved_prompt):\n",
    "    \"\"\"\n",
    "    Compare the responses to an original prompt and an improved, clearer version.\n",
    "    \n",
    "    Args:\n",
    "    original_prompt (str): The original, potentially unclear prompt\n",
    "    improved_prompt (str): An improved, clearer version of the prompt\n",
    "    \n",
    "    Returns:\n",
    "    tuple: Responses to the original and improved prompts\n",
    "    \"\"\"\n",
    "    original_response = llm.invoke(original_prompt).content\n",
    "    improved_response = llm.invoke(improved_prompt).content\n",
    "    return original_response, improved_response\n",
    "\n",
    "# Example usage\n",
    "original_prompt = \"How do I make it?\"\n",
    "improved_prompt = \"Provide a step-by-step guide for making a classic margherita pizza, including ingredients and cooking instructions.\"\n",
    "\n",
    "original_response, improved_response = compare_prompt_clarity(original_prompt, improved_prompt)\n",
    "\n",
    "print(\"Original Prompt Response:\")\n",
    "print(original_response)\n",
    "print(\"\\nImproved Prompt Response:\")\n",
    "print(improved_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured Prompts for Clarity\n",
    "\n",
    "Using structured prompts can significantly improve clarity and consistency in AI responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\", \"aspects\", \"tone\"],\n",
    "    template=\"\"\"Provide an analysis of {topic} considering the following aspects:\n",
    "    1. {{aspects[0]}}\n",
    "    2. {{aspects[1]}}\n",
    "    3. {{aspects[2]}}\n",
    "    \n",
    "    Present the analysis in a {tone} tone.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Example usage\n",
    "input_variables = {\n",
    "    \"topic\": \"the impact of social media on society\",\n",
    "    \"aspects\": [\"communication patterns\", \"mental health\", \"information spread\"],\n",
    "    \"tone\": \"balanced and objective\"\n",
    "}\n",
    "\n",
    "chain = structured_prompt | llm\n",
    "response = chain.invoke(input_variables).content\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Exercise: Improving Prompt Clarity\n",
    "\n",
    "Now, let's practice improving the clarity of prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unclear_prompts = [\n",
    "    \"What's the difference?\",\n",
    "    \"How does it work?\",\n",
    "    \"Why is it important?\"\n",
    "]\n",
    "\n",
    "def improve_prompt_clarity(unclear_prompt):\n",
    "    \"\"\"\n",
    "    Improve the clarity of a given prompt.\n",
    "    \n",
    "    Args:\n",
    "    unclear_prompt (str): The original unclear prompt\n",
    "    \n",
    "    Returns:\n",
    "    str: An improved, clearer version of the prompt\n",
    "    \"\"\"\n",
    "    improvement_prompt = f\"The following prompt is unclear: '{unclear_prompt}'. Please provide a clearer, more specific version of this prompt. output just the improved prompt and nothing else.\" \n",
    "    return llm.invoke(improvement_prompt).content\n",
    "\n",
    "for prompt in unclear_prompts:\n",
    "    improved_prompt = improve_prompt_clarity(prompt)\n",
    "    print(f\"Original: {prompt}\")\n",
    "    print(f\"Improved: {improved_prompt}\")\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
